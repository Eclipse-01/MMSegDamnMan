{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eclipse-01/MMSegDamnMan/blob/main/demo/MMSegmentation_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVmnaxFJvsb8"
      },
      "source": [
        "# MMSegmentation 教程\n",
        "欢迎来到 MMSegmentation！\n",
        "\n",
        "在本教程中，我们将演示：\n",
        "* 如何使用 MMSeg 训练权重进行推理\n",
        "* 如何在自己的数据集上训练并可视化结果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS8YHrEhbpas"
      },
      "source": [
        "## 安装 MMSegmentation\n",
        "此步骤可能需要几分钟。\n",
        "\n",
        "本教程使用 PyTorch 1.10 和 CUDA 11.1。你可以通过更改 pip install 命令中的版本号来安装其他版本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWyLrLYaNEaL",
        "outputId": "fb2f9f71-5d81-42a8-fa07-cfa4ce1a603b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 检查 nvcc 版本\n",
        "!nvcc -V\n",
        "# 检查 GCC 版本\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki3WUBjKbutg",
        "outputId": "b0846ea5-c8af-479f-de4d-d261af40527d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.12.0 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.12.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: openmim in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from openmim) (8.2.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.11/dist-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.11/dist-packages (from openmim) (0.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openmim) (2.2.2)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmim) (2.28.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (6.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (3.8)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (3.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (4.65.2)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.17.0)\n",
            "Requirement already satisfied: filelock~=3.14.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (3.14.0)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
            "Requirement already satisfied: packaging~=24.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (24.2)\n",
            "Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu124/torch2.6.0/index.html\n",
            "Collecting mmcv-full==1.6.0\n",
            "  Downloading mmcv-full-1.6.0.tar.gz (554 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m554.9/554.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv-full==1.6.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv-full==1.6.0) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv-full==1.6.0) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv-full==1.6.0) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-full==1.6.0) (6.0.2)\n",
            "Collecting yapf (from mmcv-full==1.6.0)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-full==1.6.0) (4.3.8)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv-full\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mmcv-full\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for mmcv-full\n",
            "Failed to build mmcv-full\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (mmcv-full)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 安装 PyTorch\n",
        "!pip install torch==1.12.0 torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "# 安装 MMCV\n",
        "!pip install openmim\n",
        "!mim install mmcv-full==1.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR-hHRvbNJJZ"
      },
      "outputs": [],
      "source": [
        "!rm -rf mmsegmentation\n",
        "!git clone https://github.com/open-mmlab/mmsegmentation.git\n",
        "%cd mmsegmentation\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAE_h7XhPT7d"
      },
      "outputs": [],
      "source": [
        "# 检查 Pytorch 安装\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# 检查 MMSegmentation 安装\n",
        "import mmseg\n",
        "print(mmseg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUcuC3dUv32I"
      },
      "source": [
        "## 使用 MMSeg 训练权重进行推理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hd41IGaiNet"
      },
      "outputs": [],
      "source": [
        "# 创建 checkpoints 文件夹并下载预训练权重\n",
        "!mkdir checkpoints\n",
        "!wget https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth -P checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Fxg8i-wHJE"
      },
      "outputs": [],
      "source": [
        "# 导入 MMSegmentation 推理和可视化相关 API\n",
        "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
        "from mmseg.core.evaluation import get_palette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umk8sJ0Xuace"
      },
      "outputs": [],
      "source": [
        "# 配置文件和权重文件路径\n",
        "config_file = 'configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py'\n",
        "checkpoint_file = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWlQFuTgudxu"
      },
      "outputs": [],
      "source": [
        "# 从配置文件和权重文件构建模型\n",
        "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izFv6pSRujk9"
      },
      "outputs": [],
      "source": [
        "# 测试单张图片\n",
        "img = 'demo/demo.png'\n",
        "result = inference_segmentor(model, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDcs9udgunQK"
      },
      "outputs": [],
      "source": [
        "# 显示分割结果\n",
        "show_result_pyplot(model, img, result, get_palette('cityscapes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta51clKX4cwM"
      },
      "source": [
        "## 在新数据集上训练语义分割模型\n",
        "\n",
        "要在自定义数据集上训练，需要完成以下步骤：\n",
        "1. 添加新的数据集类。\n",
        "2. 相应地创建配置文件。\n",
        "3. 执行训练和评估。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcZg6x_K5Zs3"
      },
      "source": [
        "### 添加新数据集\n",
        "\n",
        "MMSegmentation 中的数据集要求图像和语义分割标注图放在具有相同前缀的文件夹下。为了支持新数据集，可能需要修改原始文件结构。\n",
        "\n",
        "本教程以数据集转换为例。更多关于数据集重组的细节可参考[官方文档](https://github.com/open-mmlab/mmsegmentation/blob/master/docs/en/tutorials/customize_datasets.md#customize-datasets-by-reorganizing-data)。\n",
        "\n",
        "我们以 [Stanford Background Dataset](http://dags.stanford.edu/projects/scenedataset.html) 为例。该数据集包含 715 张图片，选自 [LabelMe](http://labelme.csail.mit.edu)、[MSRC](http://research.microsoft.com/en-us/projects/objectclassrecognition)、[PASCAL VOC](http://pascallin.ecs.soton.ac.uk/challenges/VOC) 和 [Geometric Context](http://www.cs.illinois.edu/homes/dhoiem/) 等公开数据集。图片主要为户外场景，每张约为 320x240 像素。\n",
        "本教程中，我们使用区域标注作为标签。共有 8 个类别，分别为：天空、树、道路、草地、水、建筑、山、前景物体。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFIt7MHq5Wls"
      },
      "outputs": [],
      "source": [
        "# 下载并解压数据集\n",
        "!wget http://dags.stanford.edu/data/iccv09Data.tar.gz -O stanford_background.tar.gz\n",
        "!tar xf stanford_background.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78LIci7F9WWI"
      },
      "outputs": [],
      "source": [
        "# 查看数据集样例\n",
        "import mmcv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = mmcv.imread('iccv09Data/images/6000124.jpg')\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(mmcv.bgr2rgb(img))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5mNQuc2GsVE"
      },
      "source": [
        "我们需要将标注转换为图像格式的语义分割图。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnGZfribFHCx"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "# 将数据集标注转换为语义分割图像\n",
        "data_root = 'iccv09Data'\n",
        "img_dir = 'images'\n",
        "ann_dir = 'labels'\n",
        "# 定义类别和调色板以便更好地可视化\n",
        "classes = ('sky', 'tree', 'road', 'grass', 'water', 'bldg', 'mntn', 'fg obj')\n",
        "palette = [[128, 128, 128], [129, 127, 38], [120, 69, 125], [53, 125, 34],\n",
        "           [0, 11, 123], [118, 20, 12], [122, 81, 25], [241, 134, 51]]\n",
        "for file in mmcv.scandir(osp.join(data_root, ann_dir), suffix='.regions.txt'):\n",
        "  seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
        "  seg_img = Image.fromarray(seg_map).convert('P')\n",
        "  seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
        "  seg_img.save(osp.join(data_root, ann_dir, file.replace('.regions.txt',\n",
        "                                                         '.png')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MCSS9ABfSks"
      },
      "outputs": [],
      "source": [
        "# 查看我们得到的分割图\n",
        "import matplotlib.patches as mpatches\n",
        "img = Image.open('iccv09Data/labels/6000124.png')\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(np.array(img.convert('RGB')))\n",
        "\n",
        "# 为每种颜色创建图例\n",
        "patches = [mpatches.Patch(color=np.array(palette[i])/255.,\n",
        "                          label=classes[i]) for i in range(8)]\n",
        "# 将图例添加到图中\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,\n",
        "           fontsize='large')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbeLYCp2k5hl"
      },
      "outputs": [],
      "source": [
        "# 随机划分训练集和验证集\n",
        "split_dir = 'splits'\n",
        "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
        "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
        "    osp.join(data_root, ann_dir), suffix='.png')]\n",
        "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
        "  # 前 4/5 作为训练集\n",
        "  train_length = int(len(filename_list)*4/5)\n",
        "  f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
        "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
        "  # 后 1/5 作为验证集\n",
        "  f.writelines(line + '\\n' for line in filename_list[train_length:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HchvmGYB_rrO"
      },
      "source": [
        "下载数据后，我们需要在新的数据集类 `StanfordBackgroundDataset` 中实现 `load_annotations` 函数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbsWOw62_o-X"
      },
      "outputs": [],
      "source": [
        "from mmseg.datasets.builder import DATASETS\n",
        "from mmseg.datasets.custom import CustomDataset\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class StanfordBackgroundDataset(CustomDataset):\n",
        "  CLASSES = classes\n",
        "  PALETTE = palette\n",
        "  def __init__(self, split, **kwargs):\n",
        "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png',\n",
        "                     split=split, **kwargs)\n",
        "    assert osp.exists(self.img_dir) and self.split is not None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUVtmn3Iq3WA"
      },
      "source": [
        "### 创建配置文件\n",
        "下一步，我们需要修改训练用的配置文件。为了加快训练过程，我们将从已有权重进行微调。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwnj9tRzqX_A"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y2oV5w97jQo"
      },
      "source": [
        "由于给定的配置文件用于在 cityscapes 数据集上训练 PSPNet，我们需要根据新数据集进行相应修改。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyKnYC1Z7iCV"
      },
      "outputs": [],
      "source": [
        "from mmseg.apis import set_random_seed\n",
        "from mmseg.utils import get_device\n",
        "\n",
        "# 由于只用一张 GPU，BN 替代 SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# 修改 decode/auxiliary head 的类别数\n",
        "cfg.model.decode_head.num_classes = 8\n",
        "cfg.model.auxiliary_head.num_classes = 8\n",
        "\n",
        "# 修改数据集类型和路径\n",
        "cfg.dataset_type = 'StanfordBackgroundDataset'\n",
        "cfg.data_root = data_root\n",
        "\n",
        "cfg.data.samples_per_gpu = 8\n",
        "cfg.data.workers_per_gpu=8\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(320, 240),\n",
        "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = img_dir\n",
        "cfg.data.train.ann_dir = ann_dir\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "cfg.data.train.split = 'splits/train.txt'\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = img_dir\n",
        "cfg.data.val.ann_dir = ann_dir\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "cfg.data.val.split = 'splits/val.txt'\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = img_dir\n",
        "cfg.data.test.ann_dir = ann_dir\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "cfg.data.test.split = 'splits/val.txt'\n",
        "\n",
        "# 仍然可以使用预训练的 Mask RCNN 权重，虽然不需要 mask 分支\n",
        "cfg.load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
        "\n",
        "# 设置工作目录用于保存文件和日志\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.runner.max_iters = 200\n",
        "cfg.log_config.interval = 10\n",
        "cfg.evaluation.interval = 200\n",
        "cfg.checkpoint_config.interval = 200\n",
        "\n",
        "# 设置随机种子以便复现结果\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.device = get_device()\n",
        "\n",
        "# 查看最终用于训练的配置\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWuH14LYF2gQ"
      },
      "source": [
        "### 训练与评估"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYKoSfdMF12B"
      },
      "outputs": [],
      "source": [
        "from mmseg.datasets import build_dataset\n",
        "from mmseg.models import build_segmentor\n",
        "from mmseg.apis import train_segmentor\n",
        "\n",
        "# 构建数据集\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# 构建分割模型\n",
        "model = build_segmentor(cfg.model)\n",
        "# 添加类别属性，方便可视化\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# 创建工作目录\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_segmentor(model, datasets, cfg, distributed=False, validate=True,\n",
        "                meta=dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEkWOP-NMbc_"
      },
      "source": [
        "使用训练好的模型进行推理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekG__UfaH_OU"
      },
      "outputs": [],
      "source": [
        "img = mmcv.imread('iccv09Data/images/6000124.jpg')\n",
        "\n",
        "model.cfg = cfg\n",
        "result = inference_segmentor(model, img)\n",
        "plt.figure(figsize=(8, 6))\n",
        "show_result_pyplot(model, img, result, palette)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c_MtuZlsDwe"
      },
      "outputs": [],
      "source": [
        "# 结束"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "MMSegmentation Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "407d2a53ddc3f8f7c4edd35e4d9b95b1c1ccdf5b3711df67dd21487022baf36e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}